{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# X_train = pd.read_csv(\"new_train.csv\")\n",
    "# X_test = pd.read_csv(\"new_test.csv\")\n",
    "X = pd.read_csv(\"new_train_1h.csv\")\n",
    "test_df = pd.read_csv(\"new_test_1h.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = X.sample(frac=0.6,random_state=200)\n",
    "evaluate_df = X.drop(train_df.index)\n",
    "\n",
    "X_train = train_df.drop(['Id','SalePrice'], axis=1)\n",
    "Y_train = train_df[\"SalePrice\"]\n",
    "X_train_full = X.drop(['Id','SalePrice'], axis=1)\n",
    "Y_train_full = X[\"SalePrice\"]\n",
    "X_eval  = evaluate_df.drop(['Id','SalePrice'], axis=1)\n",
    "Y_eval  = evaluate_df[\"SalePrice\"]\n",
    "X_test = test_df.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new = X_train[['Id','TotalSquareFeet', 'NeighborhoodOverallQualNCond', 'OverallQual', \\\n",
    "#            'ExterQual', 'NeighborhoodBldgType', 'GarageCars', 'TotRmsAbvGrd', \\\n",
    "#            'GrLivArea', 'TotalBsmtSF', 'SalePrice']]\n",
    "# X_train_new.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_new = X_test[['Id','TotalSquareFeet', 'NeighborhoodOverallQualNCond', 'OverallQual', \\\n",
    "#            'ExterQual', 'NeighborhoodBldgType', 'GarageCars', 'TotRmsAbvGrd', \\\n",
    "#            'GrLivArea', 'TotalBsmtSF']]\n",
    "# X_test_new.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_new.to_csv('new_train_limit.csv', index=False)\n",
    "# X_test_new.to_csv('new_test_limit.csv', index=False)\n",
    "# print(\"New files have been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Train = 0.02160843987064369  Evaluate = 0.1332962759446923 Full = 0.03474838513463686 Average = 0.06321770031665762 - NEW BEST!!!\n",
      "  Dropped: []\n",
      "1: Train = 0.021792834156171496  Evaluate = 0.13236501452758254 Full = 0.0349216956149938 Average = 0.06302651476624928 - NEW BEST!!!\n",
      "  Dropped: [['LotConfig_4']]\n",
      "2: Train = 0.02163909737885441  Evaluate = 0.13290614091330422 Full = 0.03458922651207918 Average = 0.0630448216014126\n",
      "3: Train = 0.021368133617347216  Evaluate = 0.1331646204557433 Full = 0.034403921121681544 Average = 0.06297889173159067 - NEW BEST!!!\n",
      "  Dropped: [['LotConfig_4'], ['Foundation_3'], ['Neighborhood_3']]\n",
      "4: Train = 0.021523511687122302  Evaluate = 0.13283964145832042 Full = 0.0345520888800066 Average = 0.06297174734181644 - NEW BEST!!!\n",
      "  Dropped: [['LotConfig_4'], ['Foundation_3'], ['Neighborhood_3'], ['BldgType_2']]\n",
      "5: Train = 0.021521506537900203  Evaluate = 0.13404810310845522 Full = 0.03449135236385331 Average = 0.06335365400340291\n",
      "6: Train = 0.021412523418256862  Evaluate = 0.1343317603726443 Full = 0.034720234299324804 Average = 0.06348817269674199\n",
      "7: Train = 0.021411618591386714  Evaluate = 0.13403354808363077 Full = 0.034782693086907034 Average = 0.06340928658730817\n",
      "8: Train = 0.021323731845501355  Evaluate = 0.13396283545015078 Full = 0.03497035061357789 Average = 0.06341897263641001\n",
      "9: Train = 0.02146066516831826  Evaluate = 0.13410653069009762 Full = 0.034763346911936374 Average = 0.06344351425678409\n",
      "10: Train = 0.021547474126267157  Evaluate = 0.13327197724044876 Full = 0.03471930185975285 Average = 0.06317958440882292\n",
      "11: Train = 0.02144770004433603  Evaluate = 0.13285886273150643 Full = 0.03445076781647837 Average = 0.06291911019744027 - NEW BEST!!!\n",
      "  Dropped: [['LotConfig_4'], ['Foundation_3'], ['Neighborhood_3'], ['BldgType_2'], ['Neighborhood_21'], ['Neighborhood_12'], ['Neighborhood_8'], ['HouseStyle_8'], ['BldgType_3'], ['HouseStyle_2'], ['Neighborhood_10']]\n",
      "12: Train = 0.022218315783117264  Evaluate = 0.13282594441083165 Full = 0.03505421862639535 Average = 0.06336615960678142\n",
      "13: Train = 0.022448872379208177  Evaluate = 0.1332665907038478 Full = 0.034806552881839356 Average = 0.0635073386549651\n",
      "14: Train = 0.02238223087982222  Evaluate = 0.13358777885939896 Full = 0.03472459685156239 Average = 0.06356486886359453\n",
      "15: Train = 0.021889579152535765  Evaluate = 0.13317632780575708 Full = 0.03468899796933524 Average = 0.06325163497587603\n",
      "16: Train = 0.022095752644000415  Evaluate = 0.13378323380543777 Full = 0.03498718664702235 Average = 0.06362205769882018\n",
      "17: Train = 0.022090203573291747  Evaluate = 0.13320195897622322 Full = 0.035072578952721874 Average = 0.06345491383407895\n",
      "18: Train = 0.022522863926744987  Evaluate = 0.13377049863313745 Full = 0.03500589496935834 Average = 0.06376641917641358\n",
      "19: Train = 0.02156340200862784  Evaluate = 0.13517858789387152 Full = 0.03501920285575607 Average = 0.06392039758608514\n",
      "20: Train = 0.02169876602196391  Evaluate = 0.13484270012120103 Full = 0.03503568514146592 Average = 0.06385905042821029\n",
      "21: Train = 0.021486240880560788  Evaluate = 0.1353801639881318 Full = 0.034980022430485536 Average = 0.06394880909972604\n",
      "22: Train = 0.022099965272750405  Evaluate = 0.13399491634966557 Full = 0.03512127993255405 Average = 0.06373872051832334\n",
      "23: Train = 0.021748525953515778  Evaluate = 0.13370927539189748 Full = 0.03515956820370606 Average = 0.06353912318303977\n",
      "24: Train = 0.021388248360902896  Evaluate = 0.13423495591309903 Full = 0.03492683767901274 Average = 0.0635166806510049\n",
      "25: Train = 0.021904389397995036  Evaluate = 0.13408931858393028 Full = 0.034901556877066364 Average = 0.06363175495299722\n",
      "26: Train = 0.02178331878421764  Evaluate = 0.13419776971654462 Full = 0.03493346999125922 Average = 0.06363818616400717\n",
      "27: Train = 0.021488267209977645  Evaluate = 0.13486371787668305 Full = 0.03467678501990976 Average = 0.06367625670219015\n",
      "28: Train = 0.021482831478986747  Evaluate = 0.13472776613345136 Full = 0.034583604358971384 Average = 0.06359806732380317\n",
      "29: Train = 0.021379446056175446  Evaluate = 0.13422553147296512 Full = 0.03462600326684443 Average = 0.063410326931995\n",
      "30: Train = 0.02121797643947794  Evaluate = 0.13465843355141088 Full = 0.03451785641502645 Average = 0.06346475546863842\n",
      "31: Train = 0.02204225849176847  Evaluate = 0.1349571810387944 Full = 0.03506340518550558 Average = 0.06402094823868948\n",
      "32: Train = 0.021688536792238144  Evaluate = 0.13538306079096687 Full = 0.03516542255013271 Average = 0.06407900671111258\n",
      "33: Train = 0.021827114523454583  Evaluate = 0.13480725660574613 Full = 0.03546254381792565 Average = 0.06403230498237546\n",
      "34: Train = 0.021855659774556686  Evaluate = 0.13473672117607108 Full = 0.03483465723502833 Average = 0.06380901272855204\n",
      "35: Train = 0.022002765830462515  Evaluate = 0.134637610351925 Full = 0.03541490827014667 Average = 0.06401842815084473\n",
      "36: Train = 0.022146891615643576  Evaluate = 0.13492002812972112 Full = 0.03493606175725479 Average = 0.06400099383420649\n",
      "37: Train = 0.021768019713566008  Evaluate = 0.13496054279740666 Full = 0.03500199412565021 Average = 0.06391018554554095\n",
      "38: Train = 0.02213782761090505  Evaluate = 0.13513213399718949 Full = 0.034820347953252846 Average = 0.06403010318711579\n",
      "39: Train = 0.0219137691919418  Evaluate = 0.13526539153834077 Full = 0.034670553795222964 Average = 0.06394990484183517\n",
      "40: Train = 0.021894979934338785  Evaluate = 0.1352913164812542 Full = 0.03479433792932592 Average = 0.06399354478163964\n",
      "41: Train = 0.021889446694545532  Evaluate = 0.13510306429342359 Full = 0.0349162888825605 Average = 0.0639695999568432\n",
      "42: Train = 0.0218479534215207  Evaluate = 0.1352575637069576 Full = 0.03451203320215944 Average = 0.06387251677687926\n",
      "43: Train = 0.021928080183386607  Evaluate = 0.13526473586775814 Full = 0.03470079915844409 Average = 0.06396453840319628\n",
      "44: Train = 0.022032041617197  Evaluate = 0.13452995021547046 Full = 0.03523825367948611 Average = 0.06393341517071785\n",
      "45: Train = 0.022706463233179885  Evaluate = 0.13482133863393572 Full = 0.036509732974438755 Average = 0.06467917828051811\n",
      "46: Train = 0.023479599193028933  Evaluate = 0.13605231488237737 Full = 0.03692637919031019 Average = 0.06548609775523884\n",
      "47: Train = 0.023571345439395878  Evaluate = 0.1361148906359198 Full = 0.0375943722138899 Average = 0.06576020276306853\n",
      "48: Train = 0.023679729124698293  Evaluate = 0.13434418829162365 Full = 0.03753287900442384 Average = 0.06518559880691525\n",
      "49: Train = 0.02338496665766235  Evaluate = 0.13410116117174609 Full = 0.037452246677521846 Average = 0.06497945816897675\n",
      "50: Train = 0.02389380268789833  Evaluate = 0.13449603234093918 Full = 0.03791133877603653 Average = 0.06543372460162468\n",
      "51: Train = 0.02395611880490962  Evaluate = 0.13402724469991506 Full = 0.03818359428840592 Average = 0.06538898593107687\n",
      "52: Train = 0.023623413749705335  Evaluate = 0.1337977264479341 Full = 0.03757136152650379 Average = 0.06499750057471441\n",
      "53: Train = 0.023652115931353863  Evaluate = 0.13509439711759752 Full = 0.03773454529009835 Average = 0.06549368611301658\n",
      "54: Train = 0.023306268817745866  Evaluate = 0.13497851427195035 Full = 0.038010437676819823 Average = 0.06543174025550534\n",
      "55: Train = 0.023593329694463275  Evaluate = 0.13519202093964877 Full = 0.03750030593495124 Average = 0.06542855218968775\n",
      "56: Train = 0.0234749859109181  Evaluate = 0.1353784451985787 Full = 0.03765801036342345 Average = 0.06550381382430674\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4e4c66c35ed7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0macc_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_log_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_boost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0macc_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_log_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_eval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_boost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0macc_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_log_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train_full\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_boost_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_full\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mavg_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0macc_train\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0macc_eval\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0macc_full\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mavg_acc\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features, base_margin)\u001b[0m\n\u001b[0;32m    598\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                                           \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                           validate_features=validate_features)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features, training)\u001b[0m\n\u001b[0;32m   1578\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m                                           \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbyref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1580\u001b[1;33m                                           ctypes.byref(preds)))\n\u001b[0m\u001b[0;32m   1581\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes2numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1582\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# grad_boost = GradientBoostingRegressor(random_state=0, n_estimators=500, max_features= 0.3)\n",
    "# grad_boost_full = GradientBoostingRegressor(random_state=0, n_estimators=500, max_features= 0.3)\n",
    "grad_boost = xgb.XGBRegressor( booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n",
    "             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n",
    "             max_depth=5, min_child_weight=1.5, n_estimators=1900, \n",
    "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
    "             reg_alpha=0.6, reg_lambda=0.6, scale_pos_weight=1, \n",
    "             silent=None, subsample=0.8, verbosity=1)\n",
    "grad_boost_full = xgb.XGBRegressor( booster='gbtree', colsample_bylevel=1,\n",
    "             colsample_bynode=1, colsample_bytree=0.6, gamma=0,\n",
    "             importance_type='gain', learning_rate=0.01, max_delta_step=0,\n",
    "             max_depth=5, min_child_weight=1.5, n_estimators=1900, \n",
    "             n_jobs=1, nthread=None, objective='reg:squarederror',\n",
    "             reg_alpha=0.6, reg_lambda=0.6, scale_pos_weight=1, \n",
    "             silent=None, subsample=0.8, verbosity=1)\n",
    "num_feat_to_drop = 1\n",
    "dropped_features = []\n",
    "i = 0\n",
    "best_acc = 1\n",
    "\n",
    "while len(X_train.columns) > 5:\n",
    "    # Train our model with the set\n",
    "    grad_boost.fit(X_train, Y_train)\n",
    "    grad_boost_full.fit(X_train_full, Y_train_full)\n",
    "    \n",
    "    # Determine our accurancy with this model\n",
    "    acc_train = np.sqrt(mean_squared_log_error(Y_train, grad_boost.predict(X_train)))\n",
    "    acc_eval = np.sqrt(mean_squared_log_error(Y_eval, grad_boost.predict(X_eval)))\n",
    "    acc_full = np.sqrt(mean_squared_log_error(Y_train_full, grad_boost_full.predict(X_train_full)))\n",
    "    avg_acc = (acc_train + acc_eval + acc_full) / 3\n",
    "    if (avg_acc >= best_acc):\n",
    "        print (f'{i}: Train = {acc_train}  Evaluate = {acc_eval} Full = {acc_full} Average = {avg_acc}')\n",
    "    else:\n",
    "        best_acc = avg_acc\n",
    "        print (f'{i}: Train = {acc_train}  Evaluate = {acc_eval} Full = {acc_full} Average = {avg_acc} - NEW BEST!!!')\n",
    "        print (f'  Dropped: {dropped_features}')\n",
    "    \n",
    "    # Determine the least important features\n",
    "    importances = pd.DataFrame({'feature':X_train.columns,'importance':np.round(grad_boost.feature_importances_,3)})\n",
    "    importances = importances.sort_values('importance',ascending=True).set_index('feature')\n",
    "    \n",
    "    # Drop the X least important features\n",
    "    features_to_drop = importances[0:num_feat_to_drop].index.tolist()\n",
    "    if len(features_to_drop) <= 0:\n",
    "        break\n",
    "    X_train.drop(features_to_drop, axis=1, inplace=True)\n",
    "    X_eval.drop(features_to_drop, axis=1, inplace=True)\n",
    "    X_train_full.drop(features_to_drop, axis=1, inplace=True)\n",
    "    dropped_features.append(features_to_drop)\n",
    "    \n",
    "    i += num_feat_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LotConfig_4',\n",
       " 'Foundation_3',\n",
       " 'Neighborhood_3',\n",
       " 'BldgType_2',\n",
       " 'Neighborhood_21',\n",
       " 'Neighborhood_12',\n",
       " 'Neighborhood_8',\n",
       " 'HouseStyle_8',\n",
       " 'BldgType_3',\n",
       " 'HouseStyle_2',\n",
       " 'Neighborhood_10']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dropped = [['LotConfig_4'], ['Foundation_3'], ['Neighborhood_3'], ['BldgType_2'], ['Neighborhood_21'], ['Neighborhood_12'], ['Neighborhood_8'], ['HouseStyle_8'], ['BldgType_3'], ['HouseStyle_2'], ['Neighborhood_10']]\n",
    "best_dropped = [x for inner in best_dropped for x in inner]\n",
    "best_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
